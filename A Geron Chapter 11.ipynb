{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6667a4af",
   "metadata": {},
   "source": [
    "# Training Deep Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a588ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#complex problems such as detecting hundreds of object types may require DNN to be trained.\n",
    "#issues we could encounter:\n",
    "    #-vanishing gradients/exploding gradients, \n",
    "    #-not enough training data\n",
    "    #-extemely slow training\n",
    "    #-severe risk of overfitting\n",
    "\n",
    "#Start with addressing the gradients issue.\n",
    "\n",
    "#vanishing gradients is when the gradient descent update leaves the lower layers connection weights unchanged\n",
    "#never converges to a solution\n",
    "#opposite is exploding gradients, where layers get extremely large weight updates.\n",
    "#generally, NNs experience unstable gradients with diff layers learning at diff speeds.\n",
    "\n",
    "#A key way around this issue is down to the initialization of the network.\n",
    "#Using Glorot/LeCun initialization. Keras uses Glorot initialization by default.\n",
    "\n",
    "#Can change to He initialization like so:\n",
    "\n",
    "    #keras.layers.Dense(10, activation='relu', kernel_initializer='he_normal')\n",
    "\n",
    "#He initialization with uniform distibution, but based on FANavg instead of FANin\n",
    "\n",
    "    #he_avg_init = keras.initializers.VarianceScaling(scale=2., mode='fan_avg', distribution='uniform')\n",
    "    #keras.layers.Dense(10, activation='relu', kernel_initializer='he_avg_init')\n",
    "\n",
    "#Choice of activation functions v important. ReLU does not saturate positive values and is fast to compute.\n",
    "#Some downsides include dying ReLUs where some neurons stop outputting anything but 0\n",
    "#This can be solved with 'leaky ReLU'. LeakyRELU(z) = max(az,z). This generally performs better, for a given leak a\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "def leaky_relu(z, alpha=0.01):\n",
    "    return np.maximum(alpha*z, z)\n",
    "\n",
    "plt.plot(z, leaky_relu(z, 0.05), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([0, 0], [-0.5, 4.2], 'k-')\n",
    "plt.grid(True)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Leak', xytext=(-3.5, 0.5), xy=(-5, -0.2), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.title(\"Leaky ReLU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.5, 4.2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50f778f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Another alternative is ELU, Exponential LU.\n",
    "#main drawback of this is that it is slower to compute than ReLU\n",
    "\n",
    "def elu(z, alpha=1):\n",
    "    return np.where(z < 0, alpha * (np.exp(z) - 1), z)\n",
    "\n",
    "plt.plot(z, elu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1, -1], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(r\"ELU activation function ($\\alpha=1$)\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24cd3ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaled ELU often significantly outperforms other activation functions. There are conditions for its use:\n",
    "#input features must be standardized\n",
    "#hidden layers weights must be initialized with LeCun\n",
    "#network architecture must be sequential.\n",
    "\n",
    "#With these conditions, SELU will self-normalize\n",
    "\n",
    "#To use leaky relu, create a leaky relu layer after the layer you apply it to.\n",
    "\n",
    "    #keras.layers.Dense(10, kernel_initializer='he_normal')\n",
    "    #keras.layers.LeakyReLU(alpha=0.2)\n",
    "    \n",
    "#for selu:\n",
    "\n",
    "    #keras.layers.Dense(10, activation='selu', kernel_initializer='lecun_normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "473f97f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using He initialization with ELU doesn't guarantee that gradients issues won't reappear during training\n",
    "#Can use Batch normalization to alleviate this.\n",
    "\n",
    "#add an operation in the model just before or after activation function which zero centers and normalizes each input\n",
    "#then scales and shifts the result\n",
    "\n",
    "#in summary, standardizes inputs, rescales, then offsets.\n",
    "#improves performance greatly on image classifiers for ex.\n",
    "#implementation looks like:\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation='elu', kernel_initializer='he_normal'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation='elu', kernel_initializer='he_normal'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66f8151a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 784)              3136      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 300)               235500    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 300)              1200      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a65c2c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batch_normalization/gamma:0', True),\n",
       " ('batch_normalization/beta:0', True),\n",
       " ('batch_normalization/moving_mean:0', False),\n",
       " ('batch_normalization/moving_variance:0', False)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check params of first BN layer\n",
    "\n",
    "[(var.name, var.trainable) for var in model.layers[1].variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2aec3998",
   "metadata": {},
   "outputs": [],
   "source": [
    "#can add the BN layers before in sequence as well:\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(100, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51a4e99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#another technique to mitigate exploding gradients is to clip them during backpropagation\n",
    "\n",
    "optimizer = keras.optimizers.SGD(clipvalue=1.0)\n",
    "\n",
    "#model.compile(loss='mse', optimizer=optimizer)\n",
    "\n",
    "#this optimizaer clips every component of the gradient vector to a value between 1 and -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8be5fcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generally, we don't want to build a DNN from scratch, try to find existing NN\n",
    "#This is transfer learning. Eg.\n",
    "\n",
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "\n",
    "def split_dataset(X, y):\n",
    "    y_5_or_6 = (y == 5) | (y == 6) # sandals or shirts\n",
    "    y_A = y[~y_5_or_6]\n",
    "    y_A[y_A > 6] -= 2 # class indices 7, 8, 9 should be moved to 5, 6, 7\n",
    "    y_B = (y[y_5_or_6] == 6).astype(np.float32) # binary classification task: is it a shirt (class 6)?\n",
    "    return ((X[~y_5_or_6], y_A),\n",
    "            (X[y_5_or_6], y_B))\n",
    "\n",
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
    "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
    "X_train_B = X_train_B[:200]\n",
    "y_train_B = y_train_B[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b076928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43986, 28, 28)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b37c3874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 28, 28)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01a0ab1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 5, 7, 7, 7, 4, 4, 3, 4, 0, 1, 6, 3, 4, 3, 2, 6, 5, 3, 4, 5,\n",
       "       1, 3, 4, 2, 0, 6, 7, 1], dtype=uint8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_A[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31b54336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_B[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1d69e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a model A\n",
    "\n",
    "model_A = keras.models.Sequential()\n",
    "model_A.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_A.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_A.add(keras.layers.Dense(8, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae977839",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6bc1d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1375/1375 [==============================] - 10s 6ms/step - loss: 0.6136 - accuracy: 0.7945 - val_loss: 0.4080 - val_accuracy: 0.8595\n",
      "Epoch 2/20\n",
      "1375/1375 [==============================] - 8s 6ms/step - loss: 0.3743 - accuracy: 0.8695 - val_loss: 0.3362 - val_accuracy: 0.8884\n",
      "Epoch 3/20\n",
      "1375/1375 [==============================] - 9s 6ms/step - loss: 0.3286 - accuracy: 0.8851 - val_loss: 0.3127 - val_accuracy: 0.8931\n",
      "Epoch 4/20\n",
      "1375/1375 [==============================] - 8s 6ms/step - loss: 0.3038 - accuracy: 0.8936 - val_loss: 0.2925 - val_accuracy: 0.8991\n",
      "Epoch 5/20\n",
      "1375/1375 [==============================] - 8s 6ms/step - loss: 0.2884 - accuracy: 0.8998 - val_loss: 0.2855 - val_accuracy: 0.9021\n",
      "Epoch 6/20\n",
      "1375/1375 [==============================] - 8s 6ms/step - loss: 0.2772 - accuracy: 0.9034 - val_loss: 0.2757 - val_accuracy: 0.9041\n",
      "Epoch 7/20\n",
      "1375/1375 [==============================] - 8s 6ms/step - loss: 0.2679 - accuracy: 0.9087 - val_loss: 0.2690 - val_accuracy: 0.9111\n",
      "Epoch 8/20\n",
      "1375/1375 [==============================] - 8s 6ms/step - loss: 0.2609 - accuracy: 0.9119 - val_loss: 0.2627 - val_accuracy: 0.9101\n",
      "Epoch 9/20\n",
      "1375/1375 [==============================] - 8s 6ms/step - loss: 0.2547 - accuracy: 0.9124 - val_loss: 0.2605 - val_accuracy: 0.9131\n",
      "Epoch 10/20\n",
      "1375/1375 [==============================] - 8s 6ms/step - loss: 0.2496 - accuracy: 0.9153 - val_loss: 0.2603 - val_accuracy: 0.9126\n",
      "Epoch 11/20\n",
      "1375/1375 [==============================] - 8s 6ms/step - loss: 0.2452 - accuracy: 0.9166 - val_loss: 0.2566 - val_accuracy: 0.9116\n",
      "Epoch 12/20\n",
      "1375/1375 [==============================] - 8s 6ms/step - loss: 0.2412 - accuracy: 0.9174 - val_loss: 0.2526 - val_accuracy: 0.9141\n",
      "Epoch 13/20\n",
      "1375/1375 [==============================] - 8s 6ms/step - loss: 0.2374 - accuracy: 0.9196 - val_loss: 0.2477 - val_accuracy: 0.9155\n",
      "Epoch 14/20\n",
      "1375/1375 [==============================] - 8s 6ms/step - loss: 0.2340 - accuracy: 0.9204 - val_loss: 0.2479 - val_accuracy: 0.9158\n",
      "Epoch 15/20\n",
      "1375/1375 [==============================] - 8s 6ms/step - loss: 0.2310 - accuracy: 0.9216 - val_loss: 0.2452 - val_accuracy: 0.9173\n",
      "Epoch 16/20\n",
      "1375/1375 [==============================] - 8s 6ms/step - loss: 0.2277 - accuracy: 0.9213 - val_loss: 0.2433 - val_accuracy: 0.9170\n",
      "Epoch 17/20\n",
      "1375/1375 [==============================] - 8s 6ms/step - loss: 0.2250 - accuracy: 0.9228 - val_loss: 0.2431 - val_accuracy: 0.9150\n",
      "Epoch 18/20\n",
      "1375/1375 [==============================] - 8s 6ms/step - loss: 0.2226 - accuracy: 0.9227 - val_loss: 0.2456 - val_accuracy: 0.9138\n",
      "Epoch 19/20\n",
      "1375/1375 [==============================] - 8s 6ms/step - loss: 0.2201 - accuracy: 0.9246 - val_loss: 0.2407 - val_accuracy: 0.9198\n",
      "Epoch 20/20\n",
      "1375/1375 [==============================] - 8s 6ms/step - loss: 0.2176 - accuracy: 0.9248 - val_loss: 0.2395 - val_accuracy: 0.9165\n"
     ]
    }
   ],
   "source": [
    "history = model_A.fit(X_train_A, y_train_A, epochs=20,\n",
    "                    validation_data=(X_valid_A, y_valid_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "269008e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save this model, we will use it to build on next\n",
    "\n",
    "model_A.save(\"my_model_A.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af8dc897",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now create your model B for binary classification\n",
    "\n",
    "model_B = keras.models.Sequential()\n",
    "model_B.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_B.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_B.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f38a056",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01f0e61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 2s 95ms/step - loss: 0.7230 - accuracy: 0.5950 - val_loss: 0.6107 - val_accuracy: 0.6389\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.5073 - accuracy: 0.7150 - val_loss: 0.4400 - val_accuracy: 0.7992\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.3715 - accuracy: 0.8800 - val_loss: 0.3563 - val_accuracy: 0.8580\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.3015 - accuracy: 0.9050 - val_loss: 0.3022 - val_accuracy: 0.8966\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.2548 - accuracy: 0.9450 - val_loss: 0.2590 - val_accuracy: 0.9249\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.2180 - accuracy: 0.9550 - val_loss: 0.2284 - val_accuracy: 0.9452\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.1910 - accuracy: 0.9650 - val_loss: 0.2057 - val_accuracy: 0.9513\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.1717 - accuracy: 0.9700 - val_loss: 0.1882 - val_accuracy: 0.9544\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.1546 - accuracy: 0.9750 - val_loss: 0.1740 - val_accuracy: 0.9594\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.1420 - accuracy: 0.9750 - val_loss: 0.1615 - val_accuracy: 0.9655\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.1311 - accuracy: 0.9750 - val_loss: 0.1518 - val_accuracy: 0.9655\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 35ms/step - loss: 0.1217 - accuracy: 0.9750 - val_loss: 0.1431 - val_accuracy: 0.9716\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 35ms/step - loss: 0.1138 - accuracy: 0.9800 - val_loss: 0.1357 - val_accuracy: 0.9706\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.1069 - accuracy: 0.9800 - val_loss: 0.1290 - val_accuracy: 0.9746\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.1001 - accuracy: 0.9850 - val_loss: 0.1236 - val_accuracy: 0.9757\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.0949 - accuracy: 0.9850 - val_loss: 0.1175 - val_accuracy: 0.9757\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.0895 - accuracy: 0.9850 - val_loss: 0.1136 - val_accuracy: 0.9767\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 37ms/step - loss: 0.0852 - accuracy: 0.9850 - val_loss: 0.1096 - val_accuracy: 0.9767\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 35ms/step - loss: 0.0818 - accuracy: 0.9850 - val_loss: 0.1060 - val_accuracy: 0.9767\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.0781 - accuracy: 0.9850 - val_loss: 0.1026 - val_accuracy: 0.9797\n"
     ]
    }
   ],
   "source": [
    "history = model_B.fit(X_train_B, y_train_B, epochs=20,\n",
    "                      validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e548d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_3 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 275,801\n",
      "Trainable params: 275,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#check the details of our model B\n",
    "\n",
    "model_B.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2ebd9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now comes the transfer learning step.\n",
    "#load all layers from model A into model B on A except for the last one\n",
    "#add another final layer for binary classification\n",
    "\n",
    "model_A = keras.models.load_model(\"my_model_A.h5\")\n",
    "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3fe5464",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a clone of model A\n",
    "\n",
    "model_A_clone = keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())\n",
    "model_B_on_A = keras.models.Sequential(model_A_clone.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf0ac546",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "                     metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "93bf1f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "7/7 [==============================] - 2s 93ms/step - loss: 0.9756 - accuracy: 0.4800 - val_loss: 0.9653 - val_accuracy: 0.5294\n",
      "Epoch 2/4\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.8995 - accuracy: 0.5150 - val_loss: 0.8986 - val_accuracy: 0.5588\n",
      "Epoch 3/4\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.8333 - accuracy: 0.5600 - val_loss: 0.8370 - val_accuracy: 0.5923\n",
      "Epoch 4/4\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.7729 - accuracy: 0.5950 - val_loss: 0.7818 - val_accuracy: 0.6298\n",
      "Epoch 1/16\n",
      "7/7 [==============================] - 2s 93ms/step - loss: 0.5911 - accuracy: 0.7100 - val_loss: 0.4469 - val_accuracy: 0.8154\n",
      "Epoch 2/16\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.3590 - accuracy: 0.8650 - val_loss: 0.3016 - val_accuracy: 0.9168\n",
      "Epoch 3/16\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.2493 - accuracy: 0.9300 - val_loss: 0.2344 - val_accuracy: 0.9473\n",
      "Epoch 4/16\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.1940 - accuracy: 0.9650 - val_loss: 0.1932 - val_accuracy: 0.9584\n",
      "Epoch 5/16\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.1581 - accuracy: 0.9850 - val_loss: 0.1654 - val_accuracy: 0.9635\n",
      "Epoch 6/16\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.1339 - accuracy: 0.9850 - val_loss: 0.1442 - val_accuracy: 0.9675\n",
      "Epoch 7/16\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.1146 - accuracy: 0.9850 - val_loss: 0.1292 - val_accuracy: 0.9726\n",
      "Epoch 8/16\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.1013 - accuracy: 0.9900 - val_loss: 0.1173 - val_accuracy: 0.9736\n",
      "Epoch 9/16\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.0904 - accuracy: 0.9900 - val_loss: 0.1074 - val_accuracy: 0.9777\n",
      "Epoch 10/16\n",
      "7/7 [==============================] - 0s 35ms/step - loss: 0.0814 - accuracy: 0.9900 - val_loss: 0.0998 - val_accuracy: 0.9797\n",
      "Epoch 11/16\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.0744 - accuracy: 0.9900 - val_loss: 0.0940 - val_accuracy: 0.9817\n",
      "Epoch 12/16\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.0690 - accuracy: 0.9950 - val_loss: 0.0886 - val_accuracy: 0.9817\n",
      "Epoch 13/16\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.0639 - accuracy: 0.9950 - val_loss: 0.0843 - val_accuracy: 0.9828\n",
      "Epoch 14/16\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 0.0805 - val_accuracy: 0.9838\n",
      "Epoch 15/16\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.0564 - accuracy: 1.0000 - val_loss: 0.0764 - val_accuracy: 0.9848\n",
      "Epoch 16/16\n",
      "7/7 [==============================] - 0s 36ms/step - loss: 0.0526 - accuracy: 1.0000 - val_loss: 0.0730 - val_accuracy: 0.9868\n"
     ]
    }
   ],
   "source": [
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4,\n",
    "                           validation_data=(X_valid_B, y_valid_B))\n",
    "\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "                     metrics=[\"accuracy\"])\n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16,\n",
    "                           validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d388dadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0999 - accuracy: 0.9785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09989636391401291, 0.9785000085830688]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now compare our results\n",
    "\n",
    "model_B.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84b03e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0729 - accuracy: 0.9900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07287653535604477, 0.9900000095367432]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B_on_A.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "089fd81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shows a great improvement through transfer learning.\n",
    "#transfer learning works best with deep CNNs.\n",
    "\n",
    "#Learning rate scheduling is another important technique\n",
    "#finding an optimal learning rate at each point of training helps to achieve a better solution.\n",
    "\n",
    "#implementing power scheduling in keras\n",
    "\n",
    "#optimizer = keras.optimizers.SGD(lr=0.01, decay=1e-4)\n",
    "\n",
    "#more detail in the text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96a28ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#avoiding overfitting through regularization\n",
    "\n",
    "#early stopping is one of the best regularization techniques.\n",
    "#other popular methods are l1, l2, dropout and maxnorm\n",
    "\n",
    "#l1 and l2 first\n",
    "\n",
    "layer = keras.layers.Dense(100, activation='elu',\n",
    "                          kernel_initializer='he_normal',\n",
    "                          kernel_regularizer=keras.regularizers.l2(0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "126fb056",
   "metadata": {},
   "outputs": [],
   "source": [
    "#you will want to apply same regularizer to each layer\n",
    "#can use partial to create a wrapper.\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "RegularizedDense = partial(keras.layers.Dense,\n",
    "                          activation='elu',\n",
    "                          kernel_initializer='he_normal',\n",
    "                          kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    RegularizedDense(300),\n",
    "    RegularizedDense(100),\n",
    "    RegularizedDense(10, activation='softmax',\n",
    "                    kernel_initializer='glorot_uniform')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "166833a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropout is a popular regularizer. randomly drops neurons during training steps.\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(300, activation='elu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation='elu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e24d5d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x2bcc0a05480>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Monte Carlo Dropout is an important technique which can boost models performance significantly. \n",
    "#Simple to implement\n",
    "\n",
    "#Final technique is max norm regularization\n",
    "\n",
    "keras.layers.Dense(100, activation='elu', kernel_initializer='he_normal',\n",
    "                  kernel_constraint=keras.constraints.max_norm(1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a46f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if a network is a stack of dense layers, it should be able to self normalize.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
